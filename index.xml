<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>孙志奇的个人博客</title>
    <link>/</link>
    <description>Recent content on 孙志奇的个人博客</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <copyright>This work is licensed under a Creative Commons Attribution-NonCommercial 4.0 International License.</copyright>
    <lastBuildDate>Wed, 26 Jun 2019 00:00:00 +0000</lastBuildDate>
    
	<atom:link href="/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>About me</title>
      <link>/about-hugo/</link>
      <pubDate>Wed, 26 Jun 2019 00:00:00 +0000</pubDate>
      
      <guid>/about-hugo/</guid>
      <description>求职简历 个人基本信息 姓 名： 孙志奇 性 别： 男 联系方式：15235926326 E-mail：carb2914@gmail.com 学历：西安理工大学 统招本科 求职意向： python全栈开发工程师 个人网站博客地址： https://sunzhiqi123.github.io/  开发技能 前端框架：Vue.js，Element-UI，Bootstrap，jQuery，Node.js 后端框架：Django，Tornado，Flask，celery 数据库：Mysql，MongoDB，Redis 项目部署：CentOS 7.6，Nginx，Fastdfs，Docker，Jenkins，SuperVisor 爬虫方面：Requests，Scrapy，Selenium，Scrapy-redis 版本控制工具：Git，Svn 其他：Golang，Sklearn，Tensor Flow，数据分析，Siege 外语：CET-4，可流畅阅读英文文档  工作经历 2017.10-- 至今 新锐泰乐科技有限公司 Python全栈开发工程师 2015.8--2017.10 思铭博达科技科技有限公司 Python初级开发工程师  项目经验 自动化运维管理系统 项目架构: Django+Mysql+Ansible+Vue+Bootstrap 项目描述： 将互联网技术、自动化技术和信息技术相结合，实现了自动化运维工作的业务处理，配置管理， 报表分析以及日常巡检等工作，高可用、准确及时的业务处理能力突破了传统运维的瓶颈，提高 企业运维服务和系统运维效率 技术重点： ·采用MVC的设计模式，降低耦合，后端采用Django框架 ·采用Bootstrap响应式设计，适用于各个平台 ·使用Supervisor管理进程，简化服务操作，降低日常维护成本 ·使用SaltStack运维工具实现自动化部署 企业信息管理系统 项目架构：Django+Bootstrap+Mysql+SaltStack+Celery 项目描述： Django-ERP是一款面向中小型企业的信息管理系统，涵盖销售管理，采购管理、库存管理、组织 管理、工单服务等，通过本系统，可以实时监控企业的收入、成本与库存，为企业的后续开 展提供准确的数据支持。 技术重点： ·基于ABAC的权限管理设计，方便集中化管理 ·采用Bootstrap响应式设计前端框架，方便leader随时审批和管理平台 ·采用JWT来保证接口数据的安全 ·采用FastDFS分布式上传文件，文件指纹避免文件重复上传 ·celery+rabbitmq异步消息队列解决消息推送失败时重新推送 车型车系品牌管理App 项目架构: Django+Scripy-Redis+Vue+Mysql+Mongodb 项目描述： 实时更新最新的车辆信息，运用协同过滤算法推荐用户喜欢的车辆类型，通过搜索的车辆信息 实现性价对比，帮助用户更快更方便地购买汽车。 项目职责： 主要用scrapy框架定时从各大汽车网站爬取车辆信息，对数据进行清洗，实现增量式爬虫，研 究一些反爬策略。 技术难点： 1.</description>
    </item>
    
    <item>
      <title>在Centos下使用Siege对Django服务进行压力测试</title>
      <link>/posts/a24/</link>
      <pubDate>Tue, 23 Apr 2019 00:00:00 +0000</pubDate>
      
      <guid>/posts/a24/</guid>
      <description>在Centos下使用Siege对Django服务进行压力测试  Siege是linux下的一个web系统的压力测试工具，支持多链接，支持get和post请求，可以对web系统进行多并发下持续请求的压力测试。今天我们就使用Siege来对Django进行一次压力测试，看看单台Django服务到底能抗住多少的并发数。 首先安装Siege wget http://download.joedog.org/siege/siege-3.0.8.tar.gz tar zxvf siege-3.0.8.tar.gz cd siege-3.0.8 ./configure make make install 验证安装结果：输入siege -V 如果输出了版本号就代表安装没问题 Siege命令常用参数 -c 200 指定并发数200 -r 5 指定测试的次数5 -f urls.txt 制定url的文件 -i internet系统，随机发送url -b 请求无需等待 delay=0 -t 5 持续测试5分钟 测试指标说明： Transactions: 4 hits 完成4次处理 Availability: 100.00 % 成功率 Elapsed time: 1.19 secs 总共用时 Data transferred: 0.03MB 共数据传输：0.03MB Response time: 0.13 secs 相应用时0.13秒，显示网络连接的速度 Transaction rate: 3.36 trans/sec平均每秒完成3.36次处理，表示服务器后台处理的速度 Throughput: 0.03MB/sec 平均每秒传送数据：0.03MB Concurrency: 0.45 最高并发数 0.</description>
    </item>
    
    <item>
      <title>在阿里云Centos7.6上面配置Mysql主从数据库(master/slave)，实现读写分离</title>
      <link>/posts/a23/</link>
      <pubDate>Mon, 22 Apr 2019 00:00:00 +0000</pubDate>
      
      <guid>/posts/a23/</guid>
      <description>#在阿里云Centos7.6上面配置Mysql主从数据库(master/slave)，实现读写分离
在之前的一篇文章中，阐述了如何在高并发高负载的场景下使用nginx做后台服务的负载均衡:在阿里云Centos上配置nginx+uwsgi+负载均衡配置,但是不要以为这样做了就是一劳永逸的，到了数据业务层、数据访问层，如果还是传统的数据结构，或者只是单单靠一台服务器负载，如此多的数据库连接操作，数据库必然会崩溃，数据库如果宕机的话，后果更是不堪设想。这时候，我们会考虑如何减少数据库的连接，一方面采用优秀的代码框架，进行代码的优化，采用优秀的数据缓存技术如：redis,如果资金丰厚的话，必然会想到架设mysql服务集群，来分担主数据库的压力。今天总结一下利用MySQL主从配置，实现读写分离，减轻数据库压力。 明确目的，部署mysql集群，采用一主一从的策略，写入操作使用主库，从库实时同步主库的数据，从库负责读取的业务，从而完成读写分离的目的。 mysql主从同步的原理很简单，从库生成两个线程，一个I/O线程，一个SQL线程；i/o线程去请求主库 的binlog（二进制日志），并将得到的binlog日志写到relay log（中继日志） 文件中；主库会生成一个 log dump 线程，用来给从库 i/o线程传binlog； SQL 线程，会读取relay log文件中的日志，并解析成具体操作，来实现主从的操作一致，而最终数据一致。 首先准备两台阿里云服务器，一台作为主机(master)，一台作为从机(slave)，都安装好mysql5.7，具体怎样安装mysql服务请移步：https://v3u.cn/a_id_72 进入master服务器 修改mysql配置文件 vim /etc/my.cnf，加入如下配置 server-id=1 innodb_flush_log_at_trx_commit=2 sync_binlog=1 log-bin=mysql-bin-1 配置说明： #设置主服务 的ID (id可以自己随便设置但是要保证和slave的id不一样) server-id=1 #设为1当然是最安全的，但性能也是最差的（相对其他两个参数而言，但不是不能接受）。如果对数据一致性和完整性要求不高，完全可以设为2，如果只最求性能，例如高并发写的日志服务器，设为0来获得更高性能 innodb_flush_log_at_trx_commit=2 #开启binlog 志同步功能 sync_binlog=1 #binlog 日志文件名 log-bin=mysql-bin-200 # 这个表示只同步某个库 (如果没有此项，表示同步所有的库) binlog-do-db=xxxx 保存后，重启mysql systemctl restart mysqld 进入mysql命令行 mysql -uroot -p你的密码 输入授权命令 GRANT REPLICATION SLAVE ON *.* to &#39;repl&#39;@&#39;%&#39; identified by &#39;Admin123!&#39;; 意思是所有slave都可以通过账号repl和密码Admin123!来同步master的数据 然后查看master的状态: show master status; 把file列和Position列记录下来，一会配置slave要用到 此时Master的配置已经搞定，登录一下从机(slave) 同理修改slave服务器的mysql配置 vim /etc/my.cnf 加入下面的配置，需要注意的是server-id不要和master一样 server-id=201 innodb_flush_log_at_trx_commit=2 sync_binlog=1 log-bin=mysql-bin-201 保存后重启服务 systemctl restart mysqld 进入mysql命令行 mysql -uroot -p你的密码 输入命令： change master to master_host=&#39;39.</description>
    </item>
    
    <item>
      <title>Django通过xlwt用文件流的方式下载excel文档</title>
      <link>/posts/a16/</link>
      <pubDate>Sun, 21 Apr 2019 00:00:00 +0000</pubDate>
      
      <guid>/posts/a16/</guid>
      <description>python3.7.2+Django2.0.4 使用django-celery遇到的那些坑 1 首先为啥要用celery 因为在Django Web平台开发中，碰到一些请求执行的任务时间较长（几分钟），为了加快用户的响应时间，因此决定采用异步任务的方式在后台执行这些任务。与此同时，celery除了异步任务，还可以开启定时任务，方便调度。 2 安装需要的软件包 pip install celery pip install celery-with-redis pip install django-celery 3 因为async这个单词在python3.7中已经作为系统关键字存在了，所以要把所有涉及到这个关键字的文件都要改掉，涉及的文件列表包含但不限于： /kombu/async /celery/utils/timer2.py /concurrency/asynpool.py /kombu/transport/redis.py /celery/worker/auto_scale.py,components,consumer,strategy 4 配置settings.py INSTALLED_APPS = ( ... &#39;djcelery&#39;, } # 末尾初始化 import djcelery djcelery.setup_loader() BROKER_URL = &#39;redis://127.0.0.1:6379/0&#39; CELERY_IMPORTS = (&#39;应用名称.task&#39;) 5 新增task.py #导入异步任务 from celery.task import task #导入定时任务库 from celery.decorators import periodic_task #利用参数来设置任务周期 @periodic_task(run_every=10) def some_task(): print(&#39;每10秒执行一次&#39;) time.sleep(5) print(&#39;执行完毕&#39;) return True #通过装饰器来注册异步任务 @task def task_mail(): #实例化一个对象 sendmail = SendMail(&#39;欢迎注册&#39;,&#39;您的验证码是1324&#39;, [&#39;599954144@qq.</description>
    </item>
    
    <item>
      <title>在阿里云Centos7.6上利用docker搭建Jenkins来自动化部署Django项目</title>
      <link>/posts/a22/</link>
      <pubDate>Sun, 21 Apr 2019 00:00:00 +0000</pubDate>
      
      <guid>/posts/a22/</guid>
      <description> 在阿里云Centos7.6上利用docker搭建Jenkins来自动化部署Django项目 一般情况下，将一个项目部署到生产环境的流程如下： 需求分析—原型设计—开发代码—内网部署-提交测试—确认上线—备份数据—外网更新-最终测试，如果发现外网部署的代码有异常，需要及时回滚。 整个过程相当复杂而漫长，其中还需要输入不少的命令，比如上传代码，git的拉取或者合并分支等等。 Jenkins是目前非常流行的一款持续集成工具，可以帮助大家把更新后的代码自动部署到服务器上运行，整个流程非常自动化，你可以理解为部署命令操作的可视化界面。 Jenkins主要有三种安装方式 下载官方war包，放到tomcat中直接运行。 yum安装。 使用官方docker镜像。 毫无疑问，既然有docker这么简单方便的工具，就没必要选择前两种复杂的安装方式了。 首先安装docker centos 安装docker 1 docker 要求 CentOS 系统的内核版本高于 3.10 ，查看本页面的前提条件来验证你的CentOS 版本是否支持 Docker 2、使用 root 权限登录 Centos。确保 yum 包更新到最新。 sudo yum update 3、卸载旧版本(如果安装过旧版本的话) sudo yum remove docker docker-common docker-selinux docker-engine 4、安装需要的软件包， yum-util 提供yum-config-manager功能，另外两个是devicemapper驱动依赖的 sudo yum install -y yum-utils device-mapper-persistent-data lvm2 5、设置yum源 sudo yum-config-manager --add-repo https://download.docker.com/linux/centos/docker-ce.repo 6、可以查看所有仓库中所有docker版本，并选择特定版本安装 yum list docker-ce --showduplicates | sort -r 7、安装docker sudo yum install docker-ce 8、启动并加入开机启动 sudo systemctl start docker sudo systemctl enable docker 9、验证安装是否成功(有client和service两部分表示docker安装启动都成功了) docker version 然后下载jenkins官方docker镜像 docker pull jenkins/jenkins 查看镜像 docker images 在主机上创建目录，并添加读写权限以便jenkins应用运行时读写文件 mkdir /root/j_node chmod 777 /root/j_node 后台将镜像以容器的形式起服务，对端口映射，同时把刚刚建立的目录挂载到容器中 docker run -d --name jenkins -p 8081:8080 -p 50000:50000 -v /root/j_node:/var/jenkins_home jenkins/jenkins 这里注意，如果是阿里云的话，安全策略需要暴露8081端口 通过网址访问 http://你的ip:8081 然后通过命令获取安装秘钥 docker logs jenkins 有了密码，输入后安装建议的插件，推荐的插件里就包含版本控制软件git。 完毕后，根据提示设置登陆账户 然后新建一个项目，在源代码控制那一栏，输入你的项目的线上git仓库地址，注意默认应该是master分支，因为生产环境部署的代码必须是主分支 保存后，点击Build Now进行部署，jenkins会自动去git版本库中抽取最新的master分支进行部署，同时每部署一次的历史记录都会被保存下来 此时，进入/root/j_node 目录下 发现项目已经部署在了workspace目录下 整个过程非常简单，每次上线之前，项目经理只需要检查各个组员的代码，然后统一合并到主分支master，最后进入jenkins点击部署按钮即可，节约了不少时间。  </description>
    </item>
    
    <item>
      <title>在阿里云服务器上使用Nginx部署https协议的网站</title>
      <link>/posts/a21/</link>
      <pubDate>Fri, 19 Apr 2019 00:00:00 +0000</pubDate>
      
      <guid>/posts/a21/</guid>
      <description>在阿里云服务器上使用Nginx部署https协议的网站  之前写过一篇文章是在阿里云服务器上用Apache切换https协议：将博客迁移阿里云并且切换成https解析的过程 这一次，换成使用Nginx来部署，相比之下，比Apache的配置要简单一些 如何申请SSL证书就按下不表了，非常简单，目前阿里云和腾讯云都免费提供一年的证书服务，区别就是腾讯云不需要域名在腾讯，而阿里云只有域名在阿里旗下才提供。 申请域名证书成功后，下载压缩包，一定要选择Nginx的证书类型，解压后得到一个key文件一个pem文件，将这两个文件上传到服务器的root目录 然后打开nginx配置文件 vim /etc/nginx/conf.d/default.conf 同时添加http和https的协议配置，需要注意的是，http需要阿里云安全协议暴露80端口,https需要阿里云安全协议暴露443端口 server { listen 80; server_name m9u.cn; #这一步是http重定向到https，也可以不写 rewrite ^(.*)$ https://${server_name}$1 permanent; access_log /root/md_vue_access.log; error_log /root/md_vue_error.log; client_max_body_size 75M; location / { root /root/fast_vue; index index.html; try_files $uri $uri/ /index.html; } error_log /root/fast_vue/error.log error; } server { listen 443; server_name m9u.cn; ssl on; ssl_certificate /root/2238250_m9u.cn.pem; ssl_certificate_key /root/2238250_m9u.cn.key; ssl_session_timeout 5m; ssl_ciphers ECDHE-RSA-AES128-GCM-SHA256:ECDHE:ECDH:AES:HIGH:!NULL:!aNULL:!MD5:!ADH:!RC4; ssl_protocols TLSv1 TLSv1.1 TLSv1.2; ssl_prefer_server_ciphers on; location / { root /root/fast_vue; index index.</description>
    </item>
    
    <item>
      <title>python3.7.3操作FastDfs来进行文件操作</title>
      <link>/posts/a20/</link>
      <pubDate>Wed, 17 Apr 2019 00:00:00 +0000</pubDate>
      
      <guid>/posts/a20/</guid>
      <description> python3.7.3操作FastDfs来进行文件操作  在之前的一篇文章中:利用Docker来搭建分布式文件系统FastDfs，我们已经搭建好了FastDfs分布式文件系统，并且已经可以通过命令进行上传操作，那么如何使用python来上传文件呢？ 很简单，还是利用docker的特性，我们知道docker 的 -v 参数，可以自动挂载宿主机的文件件到容器中去，这样宿主和容器就可以进行无障碍的文件共享，我们通过-v参数，把宿主机的root目录自动挂载到docker容器中的/var/root目录中去。 docker run -d --network=host --name tracker -v /root:/var/root delron/fastdfs tracker docker run -d --network=host --name storage -e TRACKER_SERVER=172.18.0.1:22122 -v /root:/var/root -e GROUP_NAME=group1 delron/fastdfs storage 我们又起了两个服务，一个tracker(调度)另外一个是storage(仓库),只不过都共享了宿主的文件夹/root，挂载到了/var/root下 然后分别进入宿主的命令行以及进入容器storage的命令行，发现文件夹已经共享 此时，我们可以利用docker的exec命令不进入容器，直接在宿主机的环境下调用容器内的命令，因为文件夹已经共享，所以我们输入的文件目录虽然是容器中的/var/root目录，但是实际上该上传的文件就在宿主的/root目录中，这里，我们不上传图片，而是上传一个视频 docker exec -i storage /usr/bin/fdfs_upload_file /etc/fdfs/client.conf /var/root/test.mp4 上传成功后，fastdfs将会返回视频的网络地址 浏览器访问一下，没有问题 至此，在宿主机中上传文件已经搞定，而python同样也可以在命令行中执行命令，我们可以从命令中得到URL的做法来实现django与fastdfs的交流，这里利用的是python中的os.popen方法，可以非常简单的在命令行中获取返回的fastdfs网络地址，从而避开了必须要安装fastdfs的python客户端，因为该客户端对python3并不十分友好。代码如下： import os import re std = os.popen(&amp;quot;docker exec -i storage /usr/bin/fdfs_upload_file /etc/fdfs/client.conf /var/root/test.mp4&amp;quot;).read() print(&#39;*********** fastdfs excute start ***********&#39;) print(std.strip()) print(&#39;*********** fastdfs excute end ***********&#39;) 这样，在django中上传文件时，就可以通过命令的方式上传到fastdfs中，获取返回地址后入库就可以了，本次操作将docker的特性运用到了极致，由此可见docker的泛用性之广，实实在在的提高了开发效率。  </description>
    </item>
    
    <item>
      <title>利用Docker来搭建分布式文件系统FastDfs</title>
      <link>/posts/a19/</link>
      <pubDate>Mon, 15 Apr 2019 00:00:00 +0000</pubDate>
      
      <guid>/posts/a19/</guid>
      <description> 利用Docker来搭建分布式文件系统FastDfs  对于文件存储来说，一般情况下简单的处理就是在Django配置文件中配置存储目录，按照规则对文件进行上传或者下载。 实际上，当文件较少的时候，Django是可以应付的过来的。但当文件以海量形式出现的时候，Django就并不是那么好用了，于是Fast DFS应运而出。 FastDFS是一个开源的分布式文件系统，它对文件进行管理，功能包括：文件存储、文件同步、文件访问（文件上传、文件下载）等，解决了大容量存储和负载均衡的问题。特别适合以文件为载体的在线服务，如相册网站、视频网站等等。可以说它就是为互联网而生，为大数据而生的。 FastDFS服务端有两个角色：跟踪器（tracker）和存储节点（storage）。跟踪器主要做调度工作，在访问上起负载均衡的作用。 存储节点存储文件，完成文件管理的所有功能：存储、同步和提供存取接口，FastDFS同时对文件的meta data进行管理。跟踪器和存储节点都可以由多台服务器构成。跟踪器和存储节点中的服务器均可以随时增加或下线而不会影响线上服务。其中跟踪器中的所有服务器都是对等的，可以根据服务器的压力情况随时增加或减少。 说人话，为啥要用FastDfs: 1 解决海量存储，同时存储容量扩展方便。 2 解决文件内容重复,如果用户上传的文件重复(文件指纹一样)，那么系统只有存储一份数据，值得一提的是，这项技术目前被广泛应用在网盘中。 3 结合Nginx提高网站读取图片的效率。 如果我们从头搭建fastdfs服务器那么就太low了，网上有大把的docker镜像供你选择，所以又到了利用docker优越性的时候了，首先下载fastdfs镜像 docker pull delron/fastdfs 区区四百多兆就承载了nginx和fastdfs服务 然后使用docker镜像构建tracker容器（跟踪服务器，起到调度的作用），这里tracker服务将会自动映射到宿主机上 docker run -d --network=host --name tracker -v /root:/var/root delron/fastdfs tracker 使用docker镜像构建storage容器（存储服务器，提供容量和备份服务），这里storage容器需要依赖tracker服务，传入你的tracker服务的ip地址，端口默认是22122，ip地址也就是你宿主机的ip docker run -d --network=host --name storage -e TRACKER_SERVER=192.168.99.100:22122 -v /root:/var/root -e GROUP_NAME=group1 delron/fastdfs storage 此时，命令行输入 docker ps 就可以看到两套服务都已经启动 这时，进入正在后台运行的storage容器 docker exec -it storage /bin/bash 随便下载一张图片,这个不用担心，因为在容器中如果不提交仓库的话，该图片是不会保存的 wget https://v3u.cn/v3u/Public/images/logo.png 将该图片通过命令上传到分布式系统中 /usr/bin/fdfs_upload_file /etc/fdfs/client.conf logo.png 这时该图片已上传至文件系统，并在执行该语句后返回图片存储的网络地址 最后通过浏览器访问以下存储在Fastdfs的图片，这张图片是通过nginx代理的静态资源，默认nginx监听8888端口，所以需要加上端口号，如果是在阿里云上部署，则需要暴露外部端口8888 可以看到，没有任何问题，同理，如果是视频资源，同样可以上传到fastdfs中，搞定收工。  </description>
    </item>
    
    <item>
      <title>在阿里云Centos上配置nginx&#43;uwsgi&#43;负载均衡配置</title>
      <link>/posts/a18/</link>
      <pubDate>Sat, 13 Apr 2019 00:00:00 +0000</pubDate>
      
      <guid>/posts/a18/</guid>
      <description>在阿里云Centos上配置nginx+uwsgi+负载均衡配置  负载均衡在服务端开发中算是一个比较重要的特性。因为Nginx除了作为常规的Web服务器外，还会被大规模的用于反向代理后端，Nginx的异步框架可以处理很大的并发请求，把这些并发请求hold住之后就可以分发给后台服务端(backend servers, 后面简称backend)来做复杂的计算、处理和响应，并且在业务量增加的时候可以方便地扩容后台服务器。 说白了就是，随着业务和用户规模的增长，仅仅一台服务器无法肩负起高并发的响应，所以需要两台以上的服务器共同分担压力，而分担压力的媒介就是万能的Nginx。 首先，利用wsgi在不同的端口上起两个Django服务，比如8002和8003 然后修改nginx网站配置 vim /etc/nginx/conf.d/default.conf，将原uwsgi_pass注释，改成变量绑定 server { listen 80; server_name localhost; access_log /root/myweb_access.log; error_log /root/myweb_error.log; client_max_body_size 75M; location / { include uwsgi_params; #uwsgi_pass 127.0.0.1:8000; uwsgi_pass mytest; uwsgi_param UWSGI_SCRIPT mypro.wsgi; uwsgi_param UWSGI_CHDIR /root/mypro; } location /static { alias /root/mypro/static; } } 然后修改主配置文件 vim /etc/nginx/nginx.conf，在http配置内添加负载均衡配置 http { include /etc/nginx/mime.types; default_type application/octet-stream; log_format main &#39;$remote_addr - $remote_user [$time_local] &amp;quot;$request&amp;quot; &#39; &#39;$status $body_bytes_sent &amp;quot;$http_referer&amp;quot; &#39; &#39;&amp;quot;$http_user_agent&amp;quot; &amp;quot;$http_x_forwarded_for&amp;quot;&#39;; access_log /var/log/nginx/access.</description>
    </item>
    
    <item>
      <title>golang基础</title>
      <link>/posts/a2/</link>
      <pubDate>Thu, 11 Apr 2019 00:00:00 +0000</pubDate>
      
      <guid>/posts/a2/</guid>
      <description>golang基础 1、init函数和main函数 1. golang里面有两个保留的函数：init函数（用于所有package）和main函数（只能用于package main）。(这两个函数在定义时不能有任何的参数和返回值) 2. 每个package中的init函数都是可选的，但package main就必须包含一个main函数。 3. go程序会自动调用init()和main()，所以你不需要在任何地方调用这两个函数。 4. 程序的初始化和执行都起始于main包。如果main包还导入了其它的包，那么就会在编译时将它们依次导入。 5. 等所有被导入的包都加载完毕了，就会开始对main包中的包级常量和变量进行初始化，然后执行main包中的init函数（如果存在的话），最后执行main函数。 2、调用过程 3、在main package中调用add package中变量和方法 1. 直接使用默认包名调用add中方法 package main import ( &amp;quot;LearGoProject/day1/example3/add&amp;quot; // 下面可以直接使用package名字 add 调用变量和方法 &amp;quot;fmt&amp;quot; ) func main() { add.Test() // 调用add.go中的Test()方法就会修改Name、和Age的值 fmt.Println(add.Name) // 打印add中的变量Name ：hello go fmt.Println(add.Age) // 打印add中的变量Age ：100 } package add var Name string = &amp;quot;hello world&amp;quot; // 变量名为大写才不是私有的，可以在main.go中访问 var Age int = 10 func Test() { Name = &amp;quot;hello go&amp;quot; Age = 100 } 2.</description>
    </item>
    
  </channel>
</rss>